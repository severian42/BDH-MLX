#!/usr/bin/env python3
"""Quick test script to verify BDH-MLX implementation."""

import mlx.core as mx
import bdh_mlx


def test_config():
    """Test configuration creation."""
    config = bdh_mlx.BDHConfig()
    print(f"‚úì Config created: {config}")
    assert config.vocab_size == 256
    assert config.n_layer == 6


def test_model_creation():
    """Test model instantiation."""
    config = bdh_mlx.BDHConfig(n_layer=2, n_embd=64)
    model = bdh_mlx.BDH(config)
    print("‚úì Model created successfully")
    
    # Count parameters (flatten nested dict structure)
    def count_params(params):
        total = 0
        for v in params.values():
            if isinstance(v, dict):
                total += count_params(v)
            else:
                total += v.size
        return total
    
    num_params = count_params(model.parameters())
    print(f"  Parameters: {num_params:,}")


def test_forward_pass():
    """Test forward pass."""
    config = bdh_mlx.BDHConfig(n_layer=2, n_embd=64)
    model = bdh_mlx.BDH(config)
    
    # Create dummy input (batch_size=2, seq_len=10)
    batch_size, seq_len = 2, 10
    idx = mx.random.randint(0, 256, (batch_size, seq_len))
    targets = mx.random.randint(0, 256, (batch_size, seq_len))
    
    # Forward pass
    logits, loss = model(idx, targets)
    
    print("‚úì Forward pass successful")
    print(f"  Logits shape: {logits.shape}")
    print(f"  Loss: {loss.item():.4f}")
    
    assert logits.shape == (batch_size, seq_len, config.vocab_size)
    assert loss.shape == ()


def test_generation():
    """Test text generation."""
    config = bdh_mlx.BDHConfig(n_layer=2, n_embd=64)
    model = bdh_mlx.BDH(config)
    
    # Create prompt (e.g., "Hi")
    prompt = mx.array([[72, 105]])  # "Hi" in bytes
    
    # Generate
    output = model.generate(prompt, max_new_tokens=10, temperature=1.0, top_k=50)
    
    print("‚úì Generation successful")
    print(f"  Input shape: {prompt.shape}")
    print(f"  Output shape: {output.shape}")
    print(f"  Generated bytes: {output[0].tolist()}")
    
    assert output.shape[1] == prompt.shape[1] + 10


def test_byte_encoding():
    """Test byte-level encoding/decoding."""
    text = "Hello, world! üåç"
    
    # Encode
    from train_mlx import encode_text_to_bytes, decode_bytes_to_text
    
    tokens = encode_text_to_bytes(text)
    print(f"‚úì Encoded '{text}' to {len(tokens)} bytes")
    
    # Decode
    decoded = decode_bytes_to_text(tokens)
    print(f"‚úì Decoded back to '{decoded}'")
    
    assert decoded == text


def test_rope():
    """Test Rotary Position Embedding."""
    config = bdh_mlx.BDHConfig(n_layer=1, n_embd=64, n_head=2)
    attn = bdh_mlx.Attention(config)
    
    # Create dummy query/key
    batch_size, num_heads, seq_len = 1, 2, 4
    N = config.mlp_internal_dim_multiplier * config.n_embd // config.n_head
    Q = mx.random.normal((batch_size, num_heads, seq_len, N))
    
    # Test phases
    phases = mx.random.uniform(0, 1, (batch_size, num_heads, seq_len, N))
    rotated = attn.rope(phases, Q)
    
    print("‚úì RoPE works correctly")
    print(f"  Input shape: {Q.shape}")
    print(f"  Output shape: {rotated.shape}")
    
    assert rotated.shape == Q.shape


def test_attention():
    """Test attention mechanism."""
    config = bdh_mlx.BDHConfig(n_layer=1, n_embd=64, n_head=2)
    attn = bdh_mlx.Attention(config)
    
    batch_size, num_heads, seq_len = 2, 2, 8
    N = config.mlp_internal_dim_multiplier * config.n_embd // config.n_head
    D = config.n_embd
    
    Q = mx.random.normal((batch_size, num_heads, seq_len, N))
    V = mx.random.normal((batch_size, 1, seq_len, D))
    
    output = attn(Q, Q, V)
    
    print("‚úì Attention mechanism works")
    print(f"  Q shape: {Q.shape}")
    print(f"  V shape: {V.shape}")
    print(f"  Output shape: {output.shape}")
    
    assert output.shape == V.shape


def main():
    """Run all tests."""
    print("\n" + "="*60)
    print("BDH-MLX Implementation Tests")
    print("="*60 + "\n")
    
    tests = [
        test_config,
        test_model_creation,
        test_forward_pass,
        test_generation,
        test_byte_encoding,
        test_rope,
        test_attention,
    ]
    
    for test in tests:
        print(f"\nRunning {test.__name__}...")
        try:
            test()
        except Exception as e:
            print(f"‚úó {test.__name__} failed: {e}")
            raise
    
    print("\n" + "="*60)
    print("All tests passed! ‚úì")
    print("="*60 + "\n")
    print("Ready to train with: python train_mlx.py")


if __name__ == "__main__":
    main()

